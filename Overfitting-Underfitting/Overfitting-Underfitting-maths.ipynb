{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just directly jump to mathematical explaination and we will each of these terms - Overfitting and Underfitting in our way through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to understand these concepts with the help of **Linear Regressoin**. \n",
    "\n",
    "**Our data**: Let's say we have 1 lakh examples with one feature $X$ and one response variable $Y$. Let's say we pull out 80% of the data for training and 20% for testing.\n",
    "\n",
    "So now our number of training examples are 80,000. Now: From those 80,000 examples we sample out 80,000 examples with replacement 100 times. By 'with replacement' we mean, pull out a example -> see what is it -> put it in the bag -> pull out another example, it can be same as previous one -> and so on, do this 80,000 times, for each time. Hence we have a 100 samples of 80,000 examples in each. This way we have 100 copies of training data, where every copy differs from another copy. \n",
    "\n",
    "Our samples are : $S_1, S_2, \\cdots , S_{100} $\n",
    "\n",
    "We train our linear regression on each of these samples. And for each sample, there will be the best estimate of $f(x)$ as: $\\left(\\hat{f}^1(x), \\hat{f}^2(x), \\cdots , \\hat{f}^{100}(x) \\right)$ where $\\hat{f}^i(x)\\ =\\ \\hat{\\theta}^i_0 + \\hat{\\theta}^i_1 X$ for each $i^{th}$ sample.\n",
    "\n",
    "We can say these samples are trained linear models.\n",
    "\n",
    "- Now pull out one example, say $j^{th}$ from testing data find the error between true value of that testing data and all our trained linear models for that $j^{th}$ example:\n",
    "\n",
    "$$\n",
    "\\hat{f}_1(X_j)\\ =\\ \\hat{y}^1_{j}\\\\\n",
    "\\hat{f}_2(X_j)\\ =\\ \\hat{y}^2_{j} \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{f}_{100}(X_j)\\ =\\ \\hat{y}^{100}_{j}$$\n",
    "\n",
    "It can be observed that $\\hat{y}_{j}$ has a distribution rather than a single, definite value.\n",
    "\n",
    "So, our squared error is: \n",
    "\n",
    "$$ \\text{squared error}\\ =\\ \\left(y_j - \\hat{y}_j \\right)^2$$\n",
    "\n",
    "$$\\text{We are going add and subtract }E[\\hat{y}_j] \\text{ in our above squared error as:} $$\n",
    "\n",
    "$$\\text{squared error}\\ =\\ \\left(y_j - E[\\hat{y}_j] + E[\\hat{y}_j] - \\hat{y}_j \\right)^2 $$\n",
    "\n",
    "$$\\text{applying } (a+b)^2 = a^2 + b^2 + 2ab \\\\ \\text{here,}\\ \\ \\ \\ a = y_j - E[\\hat{y}_j] \\\\ \\text{and}\\ \\ \\ \\ b = E[\\hat{y}_j] - \\hat{y}_j$$\n",
    "\n",
    "$$\\text{We get:}\\ \\ \\ \\ \\text{S.E.} = \\left(y_j - \\hat{y}_j \\right)^2 = (y_j - E[\\hat{y}_j])^2 + (E[\\hat{y}_j] - \\hat{y}_j )^2+ 2(y_j - E[\\hat{y}_j])(E[\\hat{y}_j] - \\hat{y}_j) $$\n",
    "\n",
    "Our **Mean Squared Error** for all the testing data will be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{MSE}_{test} = \\frac{1}{N_{test}} \\sum^{N_{test}}_{i=1} \\left(y_i - \\hat{y}_i \\right)^2 $$\n",
    "\n",
    "$$\\textbf{Our aim:} \\text{ to find such } \\hat{y}_i \\text{ that our } \\textbf{MSE}_{test} \\text{ is minimum}$$\n",
    "\n",
    "$$\\text{It can be written:} \\textbf{ MSE}_{test} = E[(y - \\hat{y}_i)^2] $$\n",
    "\n",
    "$$\\text{And earlier above from S.E. equation, we found what } \\left(y_j - \\hat{y}_j \\right)^2 \\text{ is equal to. Hence putting the value from above:}$$\n",
    "\n",
    "$$\\textbf{MSE} = E[(y_j - E[\\hat{y}_j])^2] + E[(E[\\hat{y}_j] - \\hat{y}_j )^2] + E[2(y_j - E[\\hat{y}_j])(E[\\hat{y}_j] - \\hat{y}_j)] $$\n",
    "\n",
    "$$Solving it further: $$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
